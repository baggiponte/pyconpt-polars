---
theme: default
layout: cover
highlighter: shiki
colorSchema: light
favicon: >-
  https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars-logo-dark.svg
title: I know Polars is fast, but my data pipelines are written in pandas!
---

# ğŸ»â€â„ï¸ I know Polars is fast
## ... _but my data pipelines are written in pandas!_

<div class="absolute bottom-10">

    ğŸ‘¤ Luca Baggi
    ğŸ’¼ ML Engineer @Futura
    ğŸ Organiser @Python Milano

</div>

<div class="absolute right-5 top-5">
<img height="150" width="150"  src="/qr-github.svg">
</div>


---

# ğŸ™‹ Raise your hand if...

<br>

<v-clicks>

ğŸ˜ You know Polars!

ğŸ” You do exploratory data analysis on a small machine?

ğŸ¼ You use pandas in production with {raw,unstructured} data...

ğŸ­ ...or perhaps a distributed system, like PySpark?

ğŸ¦† You heard of duckdb?

</v-clicks>


---

# ğŸ“ Keynote outline

<br>

<v-clicks>

## ğŸ¹ pandas is getting faster

## ğŸ»â€â„ï¸ Why should I use Polars?

## â™»ï¸ Where should I get started?

## âš¡Other features

</v-clicks>


---

# ğŸ¹ pandas is getting faster

<br>

Since v2.0.0, pandas developed a tighter integration with PyArrow, the Python implementation of **Apache Arrow memory format**. What's that?

<v-clicks>

ğŸª¶ A compact representation of in-memory data - i.e. **lower memory footprint**.

ğŸ“¦ Native support for string objects, null values, and **nested datatypes**.

ğŸ“ **Zero-copy** between libraries and languages that adopt Arrow.

ğŸ **Optimised kernels** for data operations thanks to the query engine, Acero.
</v-clicks>


---

# ğŸ¹ pandas is getting faster

<br>

PyArrow will become a required dependency from version 3.0, due next year. This enabled pandas devs to improve a lot on the library:

ğŸ“½ï¸ [Pandas 2.0 and beyond](https://www.youtube.com/watch?v=NK7RuG4rQpI) (no more "Returning a view versus a copy" ğŸ‘)

ğŸ”– [What's new in pandas 2.1?](https://towardsdatascience.com/whats-new-in-pandas-2-1-d26c0b8314a)

<v-click>

To date, only some operations leverage Acero. In other words, **some (most?) operations are still single threaded and unoptimised**.
</v-click>


---

# ğŸ»â€â„ï¸ Why should I use Polars?

<br>

<v-clicks>

ğŸ›ï¸ Utilises all **available cores on your machine**.

ğŸ› ï¸ **Optimises queries** to reduce unneeded work/memory allocations through Lazy mode.

ğŸŒŠ Can handle datasets **much larger than RAM** (e.g. streaming execution).

ğŸªº Great support for **nested datatypes**.

âœï¸ Has an expressive and elegant **syntax**!

</v-clicks>


---

# ğŸ»â€â„ï¸ Why should I use Polars?

<br>

* Polars implements Arrow.
  * If you use pandas + Arrow dtypes, you can go back and forth with (almost always) zero-copy.
* Polars query engine is [much faster](https://www.pola.rs/benchmarks.html)
  * For an overview check out [this keynote](https://www.youtube.com/watch?v=GTVm3QyJ-3I) by its creator, Ritchie Vink.
* Polars ***is* production ready**!
  * It recently crossed 2 million monthly downloads.


---

# â™»ï¸ Where should I get started?

<br>

```python
import polars as pd
```

<v-click>

Actually no ğŸ¥¸
</v-click>


---

# â™»ï¸ Where should I get started?

ğŸª  I/O

```python{1,6|3,8|4,9}
import pandas as pd

data = pd.read_*("/path/to/source.*")
data.to_*("path/to/destination.*")

import polars as pl # 100% annotated!

data = pl.read_*("/path/to/source.*")
data.write_*("path/to/destination.*")
```


---

# â™»ï¸ Where should I get started?

ğŸª  I/O but [_blazingly fast_](https://blazinglyfast.party/)

```python{1|3|7}
raw = pl.scan_*("/path/to/source.*") # creates a LazyFrame

raw = pl.scan_parquet("/path/to/*.parquet") # read_parquet works too

processed = raw.pipe(etl, *args, **kwargs)

processed.sink_parquet("path/to/destination.*")
```


---

# â™»ï¸ Where should I get started?

ğŸª  What about other formats?

```python
raw = pd.read_*("path/to/source.weird.format")

data = pl.from_pandas(raw)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: selection

```python{all|2,3|5|7,8|10,11}
raw.select(
  "col1", "col2"
  pl.col("col1", "col2"),

  pl.col(pl.DataType),      # any valid polars datatype

  pl.col("*"),
  pl.col("$A.*^]"),         # all columns that match a regex pattern

  pl.all(),
  pl.all().exclude(...)     # names, regex, types...
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: selection

```python{all|1|4-6|8,9|11|13}
from polars import selectors as cs

raw.select(
  cs.numeric(),
  ~cs.string(),
  cs.categorical(),
  
  cs.datetime(time_unit: TimeUnit | Collection[TimeUnit]),
  cs.datetime(time_zone: str | timezone | Collection[str | timezone]),

  cs.contains("substring"),

  cs.all() - cs.numeric(), # use algebra on selectors!
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: manipulate columns

```python{all|5-7|8,9}
(
  questions
  .filter(pl.col("question_times_seen").gt(5)) # also >, >=...
  .with_columns(
    # work with dates
    pl.col("start", "end").dt.day().suffix("_day"),
    pl.col("time_spent").dt.seconds().cast(pl.UInt16).alias("sec"),
    # work with strings
    pl.col("id").str.replace("uuid_", ""),
  )
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: manipulate columns

```python{5-7|8,9}
(
  questions
  .filter(pl.col("question_times_seen").gt(5)) # also >, >=...
  .with_columns(
    # work with arrays!
    pl.col("name").str.split(" ").arr.first().alias("first_name"),
    pl.col("name").str.split(" ").arr.last().alias("last_name"),
    # work with dictionaries
    pl.col("content").struct.field("nested_field")
  )
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: filtering

```python{all|4-7|5|6}
(
  raw
  .sort("simulation_created_at")
  .filter(
    (pl.col("simulation_platform").eq("Medicine"))
    & (pl.count().over("question_uid", "student_uid") == 1)
  )
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: `group_by`

```python{all|3|4-8|5|6|7}
(
  raw
  .group_by("question_uid")
  .agg(
    pl.col("correct", "time_spent").mean().suffix("_mean"),
    pl.col("student_uid").n_unique().shrink_dtype().alias("times_seen"),
    pl.col("question_category_path", "simulation_platform").first(),
  )
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: sliding windows

```python{all|3}
(
  time_series
  .group_by_rolling(index_column="dt", period="2d")
  .agg(
    [
      pl.sum("a").alias("sum_a"),
      pl.min("a").alias("min_a"),
      pl.max("a").alias("max_a"),
    ]
)
```


---

# â™»ï¸ Where should I get started?

ğŸ› ï¸ Data wrangling: window functions

```python{all|4}
(
  time_series 
  .with_columns(
    pl.col("c").min().over(["a", "b"]).suffix("_min")
  )
)
```


---

# âš¡Other (cool) features

ğŸŒ Explore the compute graph, or profile the performance

```python{all|1,2|4}
# requires graphviz
raw.filter(...).with_columns(...).show_graph(optimized=True)

result, time = raw.filter(...).with_columns(...).profile()
```


---

# âš¡Other (cool) features

ğŸš€ Even more blazingly-fasterer with `LazyFrame`s

```python{all|1|2|4-9|8}
lazy_frame = pl.scan_*(...)
lazy_frame = pl.from_pandas(...).lazy()

data_frame = (
  lazy_frame
    .filter(...)
    .with_columns(...)
    .collect() # or .sink("path/to/file.parquet")
)
```


---

# âš¡Other (cool) features

ğŸ¦† Polars can also quack SQL!

```python{all|5-8|10}
url = "https://gist.githubusercontent.com/ritchie46/cac6b337ea52281aa23c049250a4ff03/raw/89a957ff3919d90e6ef2d34235e6bf22304f3366/pokemon.csv"

pokemon = pl.read_csv(url)

ctx = pl.SQLContext(
  register_globals=True,
  eager_execution=False
)

first_five = ctx.execute("SELECT * from pokemon LIMIT 5")
```


---

# âš¡Other (cool) features

ğŸ¦† Polars can also quack SQL _from the command line_!

```bash
$ polars
Polars CLI v0.1.0
Type .help for help.
>> select * FROM read_csv('../../examples/datasets/foods1.csv');
shape: (27, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ category   â”† calories â”† fats_g â”† sugars_g â”‚
â”‚ ---        â”† ---      â”† ---    â”† ---      â”‚
â”‚ str        â”† i64      â”† f64    â”† i64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
â”‚ vegetables â”† 45       â”† 0.5    â”† 2        â”‚
â”‚ â€¦          â”† â€¦        â”† â€¦      â”† â€¦        â”‚
â”‚ fruit      â”† 50       â”† 0.0    â”† 11       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

(but it requires cargo and [building from source](https://github.com/pola-rs/polars-cli) ğŸ¥µ)!


---

# âš¡Other (cool) features

ğŸ¦† Polars can also quack SQL _from the command line_!

```bash
$ echo "SELECT category FROM read_csv('...')" | polars

shape: (27, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ category   â”‚
â”‚ ---        â”‚
â”‚ str        â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ vegetables â”‚
â”‚ â€¦          â”‚
â”‚ fruit      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---
layout: intro
---

# ğŸ™‹ Questions?

<br>

ğŸ”— Check out the [docs](https://pola-rs.github.io/polars/py-polars/html/index.html) or the [user guide](https://pola-rs.github.io/polars-book/user-guide/index.html)!

â“ Ask questions on StackOverflow with the tag [`[python-polars]`](https://stackoverflow.com/questions/tagged/python-polars) or in the (very welcoming) Discord!


---
layout: intro
---

# ğŸ™ Thank you!

<br>

Please share your feedback! My address is lucabaggi [at] duck.com

<div class="absolute right-5 top-5">
<img height="150" width="150"  src="/qr-linkedin.svg">
</div>
